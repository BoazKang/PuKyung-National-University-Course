{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d099c565-2e9b-4fc0-a2f5-6c1f155adf2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "65a08244-a5c1-4a92-9c7f-2cc26422775f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from keras.datasets import mnist\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4952ab9f-631e-46af-9e6e-d0c674a4aed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Train, Validation, Test\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2)\n",
    "y_train = to_categorical(y_train)\n",
    "y_val = to_categorical(y_val)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f399f4d-faee-476b-889a-041da9ba3897",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(-1,28*28)\n",
    "X_val = X_val.reshape(-1,28*28)\n",
    "X_test = X_test.reshape(-1,28*28)\n",
    "\n",
    "input_shape = X_train.shape[1]\n",
    "output_shape = y_train.shape[1]\n",
    "network = Sequential()\n",
    "network.add(Dense(512, activation='relu', input_shape=(input_shape,)))\n",
    "network.add(Dense(output_shape, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5fecb200-98ef-4ef1-95da-bf05b0e9525b",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = 'rmsprop'\n",
    "loss = 'categorical_crossentropy'\n",
    "metrics = ['accuracy']\n",
    "network.compile(optimizer=opt,\n",
    "                loss=loss,\n",
    "                metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f534a173-dd09-4498-9e00-c876d14b4bd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "240/240 [==============================] - 2s 5ms/step - loss: 8.8877 - accuracy: 0.8765 - val_loss: 1.4019 - val_accuracy: 0.9377\n",
      "Epoch 2/10\n",
      "240/240 [==============================] - 1s 5ms/step - loss: 0.9785 - accuracy: 0.9466 - val_loss: 0.8926 - val_accuracy: 0.9491\n",
      "Epoch 3/10\n",
      "240/240 [==============================] - 1s 5ms/step - loss: 0.5476 - accuracy: 0.9628 - val_loss: 0.7549 - val_accuracy: 0.9582\n",
      "Epoch 4/10\n",
      "240/240 [==============================] - 1s 5ms/step - loss: 0.3700 - accuracy: 0.9724 - val_loss: 0.7796 - val_accuracy: 0.9625\n",
      "Epoch 5/10\n",
      "240/240 [==============================] - 1s 5ms/step - loss: 0.3460 - accuracy: 0.9765 - val_loss: 0.8486 - val_accuracy: 0.9643\n",
      "Epoch 6/10\n",
      "240/240 [==============================] - 1s 5ms/step - loss: 0.2938 - accuracy: 0.9799 - val_loss: 0.8380 - val_accuracy: 0.9631\n",
      "Epoch 7/10\n",
      "240/240 [==============================] - 1s 5ms/step - loss: 0.2520 - accuracy: 0.9826 - val_loss: 0.8702 - val_accuracy: 0.9633\n",
      "Epoch 8/10\n",
      "240/240 [==============================] - 1s 5ms/step - loss: 0.2355 - accuracy: 0.9838 - val_loss: 0.8679 - val_accuracy: 0.9677\n",
      "Epoch 9/10\n",
      "240/240 [==============================] - 1s 5ms/step - loss: 0.2028 - accuracy: 0.9862 - val_loss: 0.8276 - val_accuracy: 0.9710\n",
      "Epoch 10/10\n",
      "240/240 [==============================] - 1s 5ms/step - loss: 0.1914 - accuracy: 0.9871 - val_loss: 0.9201 - val_accuracy: 0.9684\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1cbad2abb20>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 10\n",
    "batch_size = 200\n",
    "network.fit(X_train , \n",
    "          y_train ,\n",
    "          epochs = epochs, \n",
    "          batch_size = batch_size,\n",
    "         validation_data=(X_val,y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57a551d0-a6da-46c1-affa-89e4a30a5b33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 811us/step - loss: 0.8440 - accuracy: 0.9695\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9695000052452087"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network.evaluate(X_test,y_test)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e6a2e2d3-88ce-47e6-8eeb-9f75820c9a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd1bddd5-7c70-407d-84d1-a90c92db117a",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "815d75e2-1c94-41ee-a73c-77a18b2436f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(np.array(X_train[0])).size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8a41f7ac-8d02-4f15-8a6b-f1b175d4ec18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "218"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f7109bf8-bad2-4ffe-bb4e-7eed4f2b40d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([25000])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.apply_along_axis(len,0,X_train.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "98ff416d-0e02-4efa-9971-d3777f28e5d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        218\n",
       "1        189\n",
       "2        141\n",
       "3        550\n",
       "4        147\n",
       "        ... \n",
       "24995    180\n",
       "24996    328\n",
       "24997    184\n",
       "24998    150\n",
       "24999    153\n",
       "Length: 25000, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.Series(X_train).apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "17d28fd7-75d8-47d3-8691-e99017afe47c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9999"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max([max(sequence) for sequence in X_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9f3e7618-c9e2-4b76-8b9a-608a5cd303ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = imdb.get_word_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4b5ac1e9-7415-4403-86ed-91c403d3d1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_word = { v:k for k,v in word_index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4dca38ec-7f83-4447-98ae-443f41b0e205",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_word = []\n",
    "for i in X_train[0]:\n",
    "    X_train_word.append(index_word[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "40cb2df8-b428-4201-bbfd-ccc623145265",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the',\n",
       " 'as',\n",
       " 'you',\n",
       " 'with',\n",
       " 'out',\n",
       " 'themselves',\n",
       " 'powerful',\n",
       " 'lets',\n",
       " 'loves',\n",
       " 'their',\n",
       " 'becomes',\n",
       " 'reaching',\n",
       " 'had',\n",
       " 'journalist',\n",
       " 'of',\n",
       " 'lot',\n",
       " 'from',\n",
       " 'anyone',\n",
       " 'to',\n",
       " 'have',\n",
       " 'after',\n",
       " 'out',\n",
       " 'atmosphere',\n",
       " 'never',\n",
       " 'more',\n",
       " 'room',\n",
       " 'and',\n",
       " 'it',\n",
       " 'so',\n",
       " 'heart',\n",
       " 'shows',\n",
       " 'to',\n",
       " 'years',\n",
       " 'of',\n",
       " 'every',\n",
       " 'never',\n",
       " 'going',\n",
       " 'and',\n",
       " 'help',\n",
       " 'moments',\n",
       " 'or',\n",
       " 'of',\n",
       " 'every',\n",
       " 'chest',\n",
       " 'visual',\n",
       " 'movie',\n",
       " 'except',\n",
       " 'her',\n",
       " 'was',\n",
       " 'several',\n",
       " 'of',\n",
       " 'enough',\n",
       " 'more',\n",
       " 'with',\n",
       " 'is',\n",
       " 'now',\n",
       " 'current',\n",
       " 'film',\n",
       " 'as',\n",
       " 'you',\n",
       " 'of',\n",
       " 'mine',\n",
       " 'potentially',\n",
       " 'unfortunately',\n",
       " 'of',\n",
       " 'you',\n",
       " 'than',\n",
       " 'him',\n",
       " 'that',\n",
       " 'with',\n",
       " 'out',\n",
       " 'themselves',\n",
       " 'her',\n",
       " 'get',\n",
       " 'for',\n",
       " 'was',\n",
       " 'camp',\n",
       " 'of',\n",
       " 'you',\n",
       " 'movie',\n",
       " 'sometimes',\n",
       " 'movie',\n",
       " 'that',\n",
       " 'with',\n",
       " 'scary',\n",
       " 'but',\n",
       " 'and',\n",
       " 'to',\n",
       " 'story',\n",
       " 'wonderful',\n",
       " 'that',\n",
       " 'in',\n",
       " 'seeing',\n",
       " 'in',\n",
       " 'character',\n",
       " 'to',\n",
       " 'of',\n",
       " '70s',\n",
       " 'musicians',\n",
       " 'with',\n",
       " 'heart',\n",
       " 'had',\n",
       " 'shadows',\n",
       " 'they',\n",
       " 'of',\n",
       " 'here',\n",
       " 'that',\n",
       " 'with',\n",
       " 'her',\n",
       " 'serious',\n",
       " 'to',\n",
       " 'have',\n",
       " 'does',\n",
       " 'when',\n",
       " 'from',\n",
       " 'why',\n",
       " 'what',\n",
       " 'have',\n",
       " 'critics',\n",
       " 'they',\n",
       " 'is',\n",
       " 'you',\n",
       " 'that',\n",
       " \"isn't\",\n",
       " 'one',\n",
       " 'will',\n",
       " 'very',\n",
       " 'to',\n",
       " 'as',\n",
       " 'itself',\n",
       " 'with',\n",
       " 'other',\n",
       " 'and',\n",
       " 'in',\n",
       " 'of',\n",
       " 'seen',\n",
       " 'over',\n",
       " 'landed',\n",
       " 'for',\n",
       " 'anyone',\n",
       " 'of',\n",
       " 'and',\n",
       " 'br',\n",
       " \"show's\",\n",
       " 'to',\n",
       " 'whether',\n",
       " 'from',\n",
       " 'than',\n",
       " 'out',\n",
       " 'themselves',\n",
       " 'history',\n",
       " 'he',\n",
       " 'name',\n",
       " 'half',\n",
       " 'some',\n",
       " 'br',\n",
       " 'of',\n",
       " 'and',\n",
       " 'odd',\n",
       " 'was',\n",
       " 'two',\n",
       " 'most',\n",
       " 'of',\n",
       " 'mean',\n",
       " 'for',\n",
       " '1',\n",
       " 'any',\n",
       " 'an',\n",
       " 'boat',\n",
       " 'she',\n",
       " 'he',\n",
       " 'should',\n",
       " 'is',\n",
       " 'thought',\n",
       " 'frog',\n",
       " 'but',\n",
       " 'of',\n",
       " 'script',\n",
       " 'you',\n",
       " 'not',\n",
       " 'while',\n",
       " 'history',\n",
       " 'he',\n",
       " 'heart',\n",
       " 'to',\n",
       " 'real',\n",
       " 'at',\n",
       " 'barrel',\n",
       " 'but',\n",
       " 'when',\n",
       " 'from',\n",
       " 'one',\n",
       " 'bit',\n",
       " 'then',\n",
       " 'have',\n",
       " 'two',\n",
       " 'of',\n",
       " 'script',\n",
       " 'their',\n",
       " 'with',\n",
       " 'her',\n",
       " 'nobody',\n",
       " 'most',\n",
       " 'that',\n",
       " 'with',\n",
       " \"wasn't\",\n",
       " 'to',\n",
       " 'with',\n",
       " 'armed',\n",
       " 'acting',\n",
       " 'watch',\n",
       " 'an',\n",
       " 'for',\n",
       " 'with',\n",
       " 'heartfelt',\n",
       " 'film',\n",
       " 'want',\n",
       " 'an']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "3d3e47a1-2c03-4367-8c31-2a95edde8373",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_sequences(sequences, dimension=10000):\n",
    "    # 크기가 (len(sequences), dimension))이고 모든 원소가 0인 행렬을 만듭니다\n",
    "    results = np.zeros((len(sequences), dimension))\n",
    "    for i, sequence in enumerate(sequences):\n",
    "        results[i, sequence] = 1.  # results[i]에서 특정 인덱스의 위치를 1로 만듭니다\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "be3ef447-d46d-4e40-9fb6-51a5860c4d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = vectorize_sequences(X_train)\n",
    "X_test = vectorize_sequences(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cfd4c2bc-fdb8-4b68-abbd-c0f59b958442",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1fe1b3d5-8d88-4b3b-b022-43a67a71c69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.reshape(-1,1)\n",
    "y_val = y_val.reshape(-1,1)\n",
    "y_test = y_test.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "65d67d40-79ed-4a06-9a9b-934162ed94e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18750, 10000)\n",
      "(6250, 10000)\n",
      "(25000, 10000)\n",
      "(18750, 1)\n",
      "(6250, 1)\n",
      "(25000, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_val.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_val.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "77954d80-4af5-4fc6-918c-f77c0d29fd21",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = X_train.shape[1]\n",
    "output_shape = y_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "69d34aaa-2f9f-4f92-8ec8-a60ec6936c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(100,activation='sigmoid',input_shape=(input_shape,)))\n",
    "model.add(Dense(28,activation='tanh'))\n",
    "model.add(Dense(20,activation='relu'))\n",
    "model.add(Dense(output_shape,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e0ec9963-a5c4-44e9-a1e5-1e764fbacee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_8 (Dense)             (None, 100)               1000100   \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 28)                2828      \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 20)                580       \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 1)                 21        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,003,529\n",
      "Trainable params: 1,003,529\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f05171d0-85d5-42ab-86da-6f0ba1f2a4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = 'adam'\n",
    "# loss = 'binary_crossentropy'\n",
    "loss = 'mse'\n",
    "metrics = ['accuracy','mse']\n",
    "model.compile(optimizer=opt,\n",
    "              loss=loss,\n",
    "              metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "325c4b9c-1914-49f1-8eb0-541aa7668f5e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 1.2592e-09 - accuracy: 1.0000 - mse: 1.2592e-09 - val_loss: 0.1415 - val_accuracy: 0.8509 - val_mse: 0.1415\n",
      "Epoch 2/100\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 1.1976e-09 - accuracy: 1.0000 - mse: 1.1976e-09 - val_loss: 0.1416 - val_accuracy: 0.8506 - val_mse: 0.1416\n",
      "Epoch 3/100\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 1.1591e-09 - accuracy: 1.0000 - mse: 1.1591e-09 - val_loss: 0.1415 - val_accuracy: 0.8510 - val_mse: 0.1415\n",
      "Epoch 4/100\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 1.0948e-09 - accuracy: 1.0000 - mse: 1.0948e-09 - val_loss: 0.1416 - val_accuracy: 0.8510 - val_mse: 0.1416\n",
      "Epoch 5/100\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 1.0583e-09 - accuracy: 1.0000 - mse: 1.0583e-09 - val_loss: 0.1415 - val_accuracy: 0.8509 - val_mse: 0.1415\n",
      "Epoch 6/100\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 9.8137e-10 - accuracy: 1.0000 - mse: 9.8137e-10 - val_loss: 0.1416 - val_accuracy: 0.8510 - val_mse: 0.1416\n",
      "Epoch 7/100\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 9.5526e-10 - accuracy: 1.0000 - mse: 9.5526e-10 - val_loss: 0.1414 - val_accuracy: 0.8504 - val_mse: 0.1414\n",
      "Epoch 8/100\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 8.7858e-10 - accuracy: 1.0000 - mse: 8.7858e-10 - val_loss: 0.1417 - val_accuracy: 0.8509 - val_mse: 0.1417\n",
      "Epoch 9/100\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 8.4117e-10 - accuracy: 1.0000 - mse: 8.4117e-10 - val_loss: 0.1418 - val_accuracy: 0.8507 - val_mse: 0.1418\n",
      "Epoch 10/100\n",
      "63/63 [==============================] - 1s 15ms/step - loss: 7.9324e-10 - accuracy: 1.0000 - mse: 7.9324e-10 - val_loss: 0.1416 - val_accuracy: 0.8506 - val_mse: 0.1416\n",
      "Epoch 11/100\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 7.8632e-10 - accuracy: 1.0000 - mse: 7.8632e-10 - val_loss: 0.1415 - val_accuracy: 0.8502 - val_mse: 0.1415\n",
      "Epoch 12/100\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 7.1446e-10 - accuracy: 1.0000 - mse: 7.1446e-10 - val_loss: 0.1418 - val_accuracy: 0.8509 - val_mse: 0.1418\n",
      "Epoch 13/100\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 6.8429e-10 - accuracy: 1.0000 - mse: 6.8429e-10 - val_loss: 0.1416 - val_accuracy: 0.8504 - val_mse: 0.1416\n",
      "Epoch 14/100\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 6.6958e-10 - accuracy: 1.0000 - mse: 6.6958e-10 - val_loss: 0.1418 - val_accuracy: 0.8507 - val_mse: 0.1418\n",
      "Epoch 15/100\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 6.2614e-10 - accuracy: 1.0000 - mse: 6.2614e-10 - val_loss: 0.1418 - val_accuracy: 0.8507 - val_mse: 0.1418\n",
      "Epoch 16/100\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 6.1414e-10 - accuracy: 1.0000 - mse: 6.1414e-10 - val_loss: 0.1418 - val_accuracy: 0.8506 - val_mse: 0.1418\n",
      "Epoch 17/100\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 5.8779e-10 - accuracy: 1.0000 - mse: 5.8779e-10 - val_loss: 0.1419 - val_accuracy: 0.8510 - val_mse: 0.1419\n",
      "Epoch 18/100\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 5.6644e-10 - accuracy: 1.0000 - mse: 5.6644e-10 - val_loss: 0.1419 - val_accuracy: 0.8507 - val_mse: 0.1419\n",
      "Epoch 19/100\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 5.3841e-10 - accuracy: 1.0000 - mse: 5.3841e-10 - val_loss: 0.1419 - val_accuracy: 0.8507 - val_mse: 0.1419\n",
      "Epoch 20/100\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 5.3121e-10 - accuracy: 1.0000 - mse: 5.3121e-10 - val_loss: 0.1419 - val_accuracy: 0.8506 - val_mse: 0.1419\n",
      "Epoch 21/100\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 5.1068e-10 - accuracy: 1.0000 - mse: 5.1068e-10 - val_loss: 0.1418 - val_accuracy: 0.8506 - val_mse: 0.1418\n",
      "Epoch 22/100\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 4.9390e-10 - accuracy: 1.0000 - mse: 4.9390e-10 - val_loss: 0.1419 - val_accuracy: 0.8506 - val_mse: 0.1419\n",
      "Epoch 23/100\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 4.7560e-10 - accuracy: 1.0000 - mse: 4.7560e-10 - val_loss: 0.1420 - val_accuracy: 0.8504 - val_mse: 0.1420\n",
      "Epoch 24/100\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 4.5797e-10 - accuracy: 1.0000 - mse: 4.5797e-10 - val_loss: 0.1419 - val_accuracy: 0.8509 - val_mse: 0.1419\n",
      "Epoch 25/100\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 4.4057e-10 - accuracy: 1.0000 - mse: 4.4057e-10 - val_loss: 0.1420 - val_accuracy: 0.8506 - val_mse: 0.1420\n",
      "Epoch 26/100\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 4.2765e-10 - accuracy: 1.0000 - mse: 4.2765e-10 - val_loss: 0.1420 - val_accuracy: 0.8507 - val_mse: 0.1420\n",
      "Epoch 27/100\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 4.1477e-10 - accuracy: 1.0000 - mse: 4.1477e-10 - val_loss: 0.1420 - val_accuracy: 0.8507 - val_mse: 0.1420\n",
      "Epoch 28/100\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 4.0232e-10 - accuracy: 1.0000 - mse: 4.0232e-10 - val_loss: 0.1420 - val_accuracy: 0.8504 - val_mse: 0.1420\n",
      "Epoch 29/100\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 3.9304e-10 - accuracy: 1.0000 - mse: 3.9304e-10 - val_loss: 0.1420 - val_accuracy: 0.8509 - val_mse: 0.1420\n",
      "Epoch 30/100\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 3.7820e-10 - accuracy: 1.0000 - mse: 3.7820e-10 - val_loss: 0.1420 - val_accuracy: 0.8504 - val_mse: 0.1420\n",
      "Epoch 31/100\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 3.6833e-10 - accuracy: 1.0000 - mse: 3.6833e-10 - val_loss: 0.1421 - val_accuracy: 0.8506 - val_mse: 0.1421\n",
      "Epoch 32/100\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 3.6024e-10 - accuracy: 1.0000 - mse: 3.6024e-10 - val_loss: 0.1421 - val_accuracy: 0.8506 - val_mse: 0.1421\n",
      "Epoch 33/100\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 3.5053e-10 - accuracy: 1.0000 - mse: 3.5053e-10 - val_loss: 0.1421 - val_accuracy: 0.8507 - val_mse: 0.1421\n",
      "Epoch 34/100\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 3.4104e-10 - accuracy: 1.0000 - mse: 3.4104e-10 - val_loss: 0.1420 - val_accuracy: 0.8502 - val_mse: 0.1420\n",
      "Epoch 35/100\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 3.3242e-10 - accuracy: 1.0000 - mse: 3.3242e-10 - val_loss: 0.1421 - val_accuracy: 0.8507 - val_mse: 0.1421\n",
      "Epoch 36/100\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 3.2740e-10 - accuracy: 1.0000 - mse: 3.2740e-10 - val_loss: 0.1421 - val_accuracy: 0.8507 - val_mse: 0.1421\n",
      "Epoch 37/100\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 3.1735e-10 - accuracy: 1.0000 - mse: 3.1735e-10 - val_loss: 0.1422 - val_accuracy: 0.8509 - val_mse: 0.1422\n",
      "Epoch 38/100\n",
      "63/63 [==============================] - 1s 15ms/step - loss: 3.1050e-10 - accuracy: 1.0000 - mse: 3.1050e-10 - val_loss: 0.1421 - val_accuracy: 0.8506 - val_mse: 0.1421\n",
      "Epoch 39/100\n",
      "63/63 [==============================] - 1s 15ms/step - loss: 3.0266e-10 - accuracy: 1.0000 - mse: 3.0266e-10 - val_loss: 0.1421 - val_accuracy: 0.8502 - val_mse: 0.1421\n",
      "Epoch 40/100\n",
      "63/63 [==============================] - 1s 15ms/step - loss: 2.9461e-10 - accuracy: 1.0000 - mse: 2.9461e-10 - val_loss: 0.1422 - val_accuracy: 0.8507 - val_mse: 0.1422\n",
      "Epoch 41/100\n",
      "63/63 [==============================] - 1s 15ms/step - loss: 2.9056e-10 - accuracy: 1.0000 - mse: 2.9056e-10 - val_loss: 0.1421 - val_accuracy: 0.8506 - val_mse: 0.1421\n",
      "Epoch 42/100\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 2.8235e-10 - accuracy: 1.0000 - mse: 2.8235e-10 - val_loss: 0.1421 - val_accuracy: 0.8506 - val_mse: 0.1421\n",
      "Epoch 43/100\n",
      "63/63 [==============================] - 1s 16ms/step - loss: 2.7641e-10 - accuracy: 1.0000 - mse: 2.7641e-10 - val_loss: 0.1422 - val_accuracy: 0.8506 - val_mse: 0.1422\n",
      "Epoch 44/100\n",
      "63/63 [==============================] - 1s 15ms/step - loss: 2.7080e-10 - accuracy: 1.0000 - mse: 2.7080e-10 - val_loss: 0.1422 - val_accuracy: 0.8506 - val_mse: 0.1422\n",
      "Epoch 45/100\n",
      "63/63 [==============================] - 1s 15ms/step - loss: 2.6650e-10 - accuracy: 1.0000 - mse: 2.6650e-10 - val_loss: 0.1422 - val_accuracy: 0.8506 - val_mse: 0.1422\n",
      "Epoch 46/100\n",
      "63/63 [==============================] - 1s 16ms/step - loss: 2.6090e-10 - accuracy: 1.0000 - mse: 2.6090e-10 - val_loss: 0.1422 - val_accuracy: 0.8506 - val_mse: 0.1422\n",
      "Epoch 47/100\n",
      "63/63 [==============================] - 1s 15ms/step - loss: 2.5423e-10 - accuracy: 1.0000 - mse: 2.5423e-10 - val_loss: 0.1422 - val_accuracy: 0.8502 - val_mse: 0.1422\n",
      "Epoch 48/100\n",
      "63/63 [==============================] - 1s 15ms/step - loss: 2.5024e-10 - accuracy: 1.0000 - mse: 2.5024e-10 - val_loss: 0.1422 - val_accuracy: 0.8509 - val_mse: 0.1422\n",
      "Epoch 49/100\n",
      "63/63 [==============================] - 1s 15ms/step - loss: 2.4612e-10 - accuracy: 1.0000 - mse: 2.4612e-10 - val_loss: 0.1422 - val_accuracy: 0.8509 - val_mse: 0.1422\n",
      "Epoch 50/100\n",
      "63/63 [==============================] - 1s 15ms/step - loss: 2.4221e-10 - accuracy: 1.0000 - mse: 2.4221e-10 - val_loss: 0.1422 - val_accuracy: 0.8507 - val_mse: 0.1422\n",
      "Epoch 51/100\n",
      "63/63 [==============================] - 1s 16ms/step - loss: 2.3582e-10 - accuracy: 1.0000 - mse: 2.3582e-10 - val_loss: 0.1422 - val_accuracy: 0.8506 - val_mse: 0.1422\n",
      "Epoch 52/100\n",
      "63/63 [==============================] - 1s 15ms/step - loss: 2.3274e-10 - accuracy: 1.0000 - mse: 2.3274e-10 - val_loss: 0.1422 - val_accuracy: 0.8502 - val_mse: 0.1422\n",
      "Epoch 53/100\n",
      "63/63 [==============================] - 1s 15ms/step - loss: 2.2845e-10 - accuracy: 1.0000 - mse: 2.2845e-10 - val_loss: 0.1422 - val_accuracy: 0.8506 - val_mse: 0.1422\n",
      "Epoch 54/100\n",
      "63/63 [==============================] - 1s 15ms/step - loss: 2.2350e-10 - accuracy: 1.0000 - mse: 2.2350e-10 - val_loss: 0.1422 - val_accuracy: 0.8502 - val_mse: 0.1422\n",
      "Epoch 55/100\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 2.1975e-10 - accuracy: 1.0000 - mse: 2.1975e-10 - val_loss: 0.1422 - val_accuracy: 0.8504 - val_mse: 0.1422\n",
      "Epoch 56/100\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 2.1613e-10 - accuracy: 1.0000 - mse: 2.1613e-10 - val_loss: 0.1422 - val_accuracy: 0.8502 - val_mse: 0.1422\n",
      "Epoch 57/100\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 2.1245e-10 - accuracy: 1.0000 - mse: 2.1245e-10 - val_loss: 0.1423 - val_accuracy: 0.8509 - val_mse: 0.1423\n",
      "Epoch 58/100\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 2.0923e-10 - accuracy: 1.0000 - mse: 2.0923e-10 - val_loss: 0.1422 - val_accuracy: 0.8504 - val_mse: 0.1422\n",
      "Epoch 59/100\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 2.0571e-10 - accuracy: 1.0000 - mse: 2.0571e-10 - val_loss: 0.1423 - val_accuracy: 0.8506 - val_mse: 0.1423\n",
      "Epoch 60/100\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 2.0214e-10 - accuracy: 1.0000 - mse: 2.0214e-10 - val_loss: 0.1423 - val_accuracy: 0.8507 - val_mse: 0.1423\n",
      "Epoch 61/100\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 1.9897e-10 - accuracy: 1.0000 - mse: 1.9897e-10 - val_loss: 0.1423 - val_accuracy: 0.8507 - val_mse: 0.1423\n",
      "Epoch 62/100\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 1.9618e-10 - accuracy: 1.0000 - mse: 1.9618e-10 - val_loss: 0.1423 - val_accuracy: 0.8509 - val_mse: 0.1423\n",
      "Epoch 63/100\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 1.9322e-10 - accuracy: 1.0000 - mse: 1.9322e-10 - val_loss: 0.1423 - val_accuracy: 0.8507 - val_mse: 0.1423\n",
      "Epoch 64/100\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 1.9008e-10 - accuracy: 1.0000 - mse: 1.9008e-10 - val_loss: 0.1423 - val_accuracy: 0.8504 - val_mse: 0.1423\n",
      "Epoch 65/100\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 1.8772e-10 - accuracy: 1.0000 - mse: 1.8772e-10 - val_loss: 0.1423 - val_accuracy: 0.8504 - val_mse: 0.1423\n",
      "Epoch 66/100\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 1.8453e-10 - accuracy: 1.0000 - mse: 1.8453e-10 - val_loss: 0.1423 - val_accuracy: 0.8509 - val_mse: 0.1423\n",
      "Epoch 67/100\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 1.8294e-10 - accuracy: 1.0000 - mse: 1.8294e-10 - val_loss: 0.1424 - val_accuracy: 0.8507 - val_mse: 0.1424\n",
      "Epoch 68/100\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 1.7998e-10 - accuracy: 1.0000 - mse: 1.7998e-10 - val_loss: 0.1423 - val_accuracy: 0.8506 - val_mse: 0.1423\n",
      "Epoch 69/100\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 1.7676e-10 - accuracy: 1.0000 - mse: 1.7676e-10 - val_loss: 0.1423 - val_accuracy: 0.8506 - val_mse: 0.1423\n",
      "Epoch 70/100\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 1.7432e-10 - accuracy: 1.0000 - mse: 1.7432e-10 - val_loss: 0.1424 - val_accuracy: 0.8509 - val_mse: 0.1424\n",
      "Epoch 71/100\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 1.7167e-10 - accuracy: 1.0000 - mse: 1.7167e-10 - val_loss: 0.1424 - val_accuracy: 0.8509 - val_mse: 0.1424\n",
      "Epoch 72/100\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 1.6996e-10 - accuracy: 1.0000 - mse: 1.6996e-10 - val_loss: 0.1423 - val_accuracy: 0.8509 - val_mse: 0.1423\n",
      "Epoch 73/100\n",
      "63/63 [==============================] - 1s 15ms/step - loss: 1.6720e-10 - accuracy: 1.0000 - mse: 1.6720e-10 - val_loss: 0.1424 - val_accuracy: 0.8509 - val_mse: 0.1424\n",
      "Epoch 74/100\n",
      "63/63 [==============================] - 1s 15ms/step - loss: 1.6514e-10 - accuracy: 1.0000 - mse: 1.6514e-10 - val_loss: 0.1424 - val_accuracy: 0.8506 - val_mse: 0.1424\n",
      "Epoch 75/100\n",
      "63/63 [==============================] - 1s 15ms/step - loss: 1.6280e-10 - accuracy: 1.0000 - mse: 1.6280e-10 - val_loss: 0.1423 - val_accuracy: 0.8506 - val_mse: 0.1423\n",
      "Epoch 76/100\n",
      "63/63 [==============================] - 1s 15ms/step - loss: 1.6097e-10 - accuracy: 1.0000 - mse: 1.6097e-10 - val_loss: 0.1424 - val_accuracy: 0.8504 - val_mse: 0.1424\n",
      "Epoch 77/100\n",
      "63/63 [==============================] - 1s 15ms/step - loss: 1.5860e-10 - accuracy: 1.0000 - mse: 1.5860e-10 - val_loss: 0.1424 - val_accuracy: 0.8507 - val_mse: 0.1424\n",
      "Epoch 78/100\n",
      "63/63 [==============================] - 1s 15ms/step - loss: 1.5686e-10 - accuracy: 1.0000 - mse: 1.5686e-10 - val_loss: 0.1424 - val_accuracy: 0.8506 - val_mse: 0.1424\n",
      "Epoch 79/100\n",
      "63/63 [==============================] - 1s 15ms/step - loss: 1.5463e-10 - accuracy: 1.0000 - mse: 1.5463e-10 - val_loss: 0.1424 - val_accuracy: 0.8506 - val_mse: 0.1424\n",
      "Epoch 80/100\n",
      "63/63 [==============================] - 1s 15ms/step - loss: 1.5351e-10 - accuracy: 1.0000 - mse: 1.5351e-10 - val_loss: 0.1424 - val_accuracy: 0.8504 - val_mse: 0.1424\n",
      "Epoch 81/100\n",
      "63/63 [==============================] - 1s 15ms/step - loss: 1.5145e-10 - accuracy: 1.0000 - mse: 1.5145e-10 - val_loss: 0.1424 - val_accuracy: 0.8507 - val_mse: 0.1424\n",
      "Epoch 82/100\n",
      "63/63 [==============================] - 1s 15ms/step - loss: 1.4959e-10 - accuracy: 1.0000 - mse: 1.4959e-10 - val_loss: 0.1424 - val_accuracy: 0.8506 - val_mse: 0.1424\n",
      "Epoch 83/100\n",
      "63/63 [==============================] - 1s 15ms/step - loss: 1.4763e-10 - accuracy: 1.0000 - mse: 1.4763e-10 - val_loss: 0.1424 - val_accuracy: 0.8506 - val_mse: 0.1424\n",
      "Epoch 84/100\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 1.4618e-10 - accuracy: 1.0000 - mse: 1.4618e-10 - val_loss: 0.1424 - val_accuracy: 0.8506 - val_mse: 0.1424\n",
      "Epoch 85/100\n",
      "63/63 [==============================] - 1s 15ms/step - loss: 1.4430e-10 - accuracy: 1.0000 - mse: 1.4430e-10 - val_loss: 0.1424 - val_accuracy: 0.8506 - val_mse: 0.1424\n",
      "Epoch 86/100\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 1.4220e-10 - accuracy: 1.0000 - mse: 1.4220e-10 - val_loss: 0.1424 - val_accuracy: 0.8507 - val_mse: 0.1424\n",
      "Epoch 87/100\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 1.4060e-10 - accuracy: 1.0000 - mse: 1.4060e-10 - val_loss: 0.1424 - val_accuracy: 0.8506 - val_mse: 0.1424\n",
      "Epoch 88/100\n",
      " 1/63 [..............................] - ETA: 0s - loss: 1.4588e-10 - accuracy: 1.0000 - mse: 1.4588e-10"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_3100/107925713.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m300\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m model.fit(X_train,\n\u001b[0m\u001b[0;32m      4\u001b[0m           \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1382\u001b[0m                 _r=1):\n\u001b[0;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1384\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1385\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    913\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    914\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 915\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    945\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    946\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 947\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    948\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    949\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2954\u001b[0m       (graph_function,\n\u001b[0;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2956\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   2957\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   2958\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1851\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1852\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1853\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1854\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    498\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 499\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    500\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    501\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "batch_size = 300\n",
    "model.fit(X_train,\n",
    "          y_train,\n",
    "          epochs=epochs,\n",
    "          batch_size=batch_size,\n",
    "          validation_data=(X_val,y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2d57324f-31f0-49e8-89da-0187465cae62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c2382a07-506c-4f26-ad0c-de9171375f48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "3ba6ae61-aab1-4fc6-b80f-f5eaf5978a94",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1cbb1b910a0>]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:240: RuntimeWarning: Glyph 8722 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:203: RuntimeWarning: Glyph 8722 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(model.history.history['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "0a84d5de-e10b-4da3-b46a-17c1f118ebe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import reuters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "8ff25f48-ae24-47e9-bc37-7653e6643b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = reuters.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "8890be77-61c0-4050-8b40-eed2fe4c25c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8982,), (2246,), (8982,), (2246,))"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "a77bff56-7e7d-4322-80a1-d9549e0e6542",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 27595 is out of bounds for axis 1 with size 10000",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_3100/2617814373.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvectorize_sequences\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mX_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvectorize_sequences\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_3100/803790893.py\u001b[0m in \u001b[0;36mvectorize_sequences\u001b[1;34m(sequences, dimension)\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msequences\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdimension\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msequence\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msequences\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m         \u001b[0mresults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msequence\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1.\u001b[0m  \u001b[1;31m# results[i]에서 특정 인덱스의 위치를 1로 만듭니다\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 27595 is out of bounds for axis 1 with size 10000"
     ]
    }
   ],
   "source": [
    "X_train = vectorize_sequences(X_train)\n",
    "X_test = vectorize_sequences(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced401b8-19b3-4bed-aa64-ff1dd59f5d34",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
